{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "<center><h1  style=\"color:white; background-color:#000000; border-radius: 0px; padding:25px;\"> Rules extraction </h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "This notebook aim at evaluating different classiifer (including rules evaluation) on several learning tasks (classificationa nd regression)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import os\n",
    "os.chdir('../')\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir('reproduce-exp', exist_ok=True) # create output directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "# Protocol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score, accuracy_score,roc_auc_score,mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from woodtapper.extract_rules import SirusClassifier,SirusRegressor\n",
    "from woodtapper.extract_rules.visualization import show_rules\n",
    "from data.data import load_titatnic_benard_data, load_houses_sales_reg_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from sklearn.model_selection import StratifiedKFold, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_folds(X, y, output_path=\"data_with_folds.csv\", stratified=True, n_splits=5, random_state=0):\n",
    "    \"\"\"\n",
    "    Create a 5-fold split and save a CSV file with fold assignments.\n",
    "    \"\"\"\n",
    "    # Convert to DataFrame if needed\n",
    "    if not isinstance(X, pd.DataFrame):\n",
    "        X = pd.DataFrame(X)\n",
    "    if not isinstance(y, (pd.Series, pd.DataFrame)):\n",
    "        y = pd.Series(y, name=\"target\")\n",
    "\n",
    "    # Combine\n",
    "    df = X.copy()\n",
    "    df[\"target\"] = y.values\n",
    "\n",
    "    # Initialize splitter\n",
    "    if stratified:\n",
    "        kf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    else:\n",
    "        kf = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "\n",
    "    # Assign folds\n",
    "    df[\"fold\"] = -1\n",
    "    for fold, (_, val_idx) in enumerate(kf.split(X, y)):\n",
    "        df.loc[val_idx, \"fold\"] = fold\n",
    "\n",
    "    # Save\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"âœ… File saved: {output_path}\")\n",
    "    return df\n",
    "\n",
    "def cross_validate_from_csv(csv_path_data,csv_path_preds,\n",
    "                            model, target_col=\"target\", fold_col=\"fold\", is_clf=True):\n",
    "    \"\"\"\n",
    "    Perform cross-validation using a CSV with preassigned folds.\n",
    "\n",
    "    Parameters:\n",
    "    - csv_path: path to CSV file with 'fold' column\n",
    "    - model_class: scikit-learn estimator class (not an instance)\n",
    "    - target_col: name of target column\n",
    "    - fold_col: name of fold column\n",
    "    - model_params: dictionary of parameters to pass to the model\n",
    "    - classification_threshold: for binary classification with probabilities\n",
    "\n",
    "    Returns:\n",
    "    - DataFrame with fold metrics\n",
    "    \"\"\"\n",
    "    #if model_params is None:\n",
    "    #    model_params = {}\n",
    "\n",
    "    df = pd.read_csv(csv_path_data)\n",
    "    folds = sorted(df[fold_col].unique())\n",
    "    results = []\n",
    "    list_preds = []\n",
    "    list_folds = []\n",
    "    for f in folds:\n",
    "        train_df = df[df[fold_col] != f]\n",
    "        test_df  = df[df[fold_col] == f]\n",
    "\n",
    "        X_train = train_df.drop(columns=[target_col, fold_col])\n",
    "        y_train = train_df[target_col]\n",
    "        X_test  = test_df.drop(columns=[target_col, fold_col])\n",
    "        y_test  = test_df[target_col]\n",
    "        list_folds.extend([f]*len(y_test))\n",
    "\n",
    "        # Instantiate and fit the model\n",
    "        #model = model_class(**model_params)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        if is_clf:\n",
    "            preds = model.predict_proba(X_test)\n",
    "            names= ['fold','class_0','class_1']\n",
    "        else:\n",
    "            preds = model.predict(X_test)\n",
    "            names= ['fold','pred']\n",
    "        list_preds.extend(list(preds))\n",
    "    if is_clf:\n",
    "        res_final = np.concatenate((np.array(list_folds).reshape(-1,1),np.array(list_preds)), axis=1)\n",
    "    else:\n",
    "        res_final = np.concatenate((np.array(list_folds).reshape(-1,1),np.array(list_preds).reshape(-1,1)), axis=1)\n",
    "    pd.DataFrame(res_final,columns=names).to_csv(csv_path_preds, index=False)\n",
    "\n",
    "def compute_metrics_csv(csv_path_data,csv_path_preds,col_preds=\"class_1\", \n",
    "                        type_learning=\"clf\", target_col=\"target\",fold_col=\"fold\", classification_threshold=0.5):\n",
    "\n",
    "    df = pd.read_csv(csv_path_data)\n",
    "    folds = sorted(df[fold_col].unique())\n",
    "    df_preds = pd.read_csv(csv_path_preds)\n",
    "    results_metric1 = []\n",
    "    results_metric2 = []\n",
    "\n",
    "    #start_row = 0\n",
    "    for f in folds:\n",
    "        test_df  = df[df[fold_col] == f]\n",
    "        y_test  = test_df[target_col].to_numpy().ravel()\n",
    "        \n",
    "        df_preds_tests = df_preds[df_preds[fold_col] == f]\n",
    "        preds_probas = df_preds_tests[col_preds].to_numpy().ravel()\n",
    "        #preds_probas  = df_preds.iloc[start_row:start_row+len(y_test),index_col_target].to_numpy()\n",
    "        #start_row += len(y_test) # Update for next fold\n",
    "\n",
    "        # Determine metric\n",
    "        if type_learning == 'clf':  # Classification\n",
    "            preds_ = (preds_probas >= classification_threshold).astype(int)\n",
    "            \n",
    "            metric = accuracy_score(y_test, preds_)\n",
    "            metric_name = \"accuracy\"\n",
    "            metric2 = roc_auc_score(y_test,preds_probas)\n",
    "            metric_name2 = \"roc_auc\"\n",
    "        else:  # Regression\n",
    "            metric = sqrt(mean_squared_error(y_test, preds_probas))\n",
    "            metric_name = \"MSE\"\n",
    "            metric2 = mean_absolute_error(y_test,preds_probas)\n",
    "            metric_name2 = \"MAE\"\n",
    "            \n",
    "        print(f\"Fold {f} - {metric_name}: {metric:.4f}\")\n",
    "        results_metric1.append({\"fold\": f, metric_name: metric})\n",
    "        print(f\"Fold {f} - {metric_name2}: {metric2:.4f}\")\n",
    "        results_metric2.append({\"fold\": f, metric_name2: metric2})\n",
    "\n",
    "    results_df_metric1 = pd.DataFrame(results_metric1)\n",
    "    results_df_metric2 = pd.DataFrame(results_metric2)\n",
    "    print(\"\\n=== Overall Results ===\")\n",
    "    print(results_df_metric1)\n",
    "    print(f\"Mean {metric_name}: {results_df_metric1[metric_name].mean():.4f} with std {results_df_metric1[metric_name].std():.4f}\")\n",
    "    print(results_df_metric2)\n",
    "    print(f\"Mean {metric_name2}: {results_df_metric2[metric_name2].mean():.4f} with std {results_df_metric2[metric_name2].std():.4f}\")\n",
    "\n",
    "    return results_df_metric1,results_df_metric2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "# Clf:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Titanic:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "### rules: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_titanic, y_titanic = load_titatnic_benard_data()\n",
    "#df_titanic = load_titatnic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(y_titanic)[1] / (Counter(y_titanic)[0] + Counter(y_titanic)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RandomForestClassifier rules extraction\n",
    "RFSirus = SirusClassifier(n_estimators=2000,max_depth=2,quantile=10,p0=0.0,max_n_rules=25,max_features=6,\n",
    "                            to_not_binarize_colindexes=[1,3,4],\n",
    "                            starting_index_one_hot=None,bootstrap=True,\n",
    "                            random_state=0,splitter=\"quantile\")\n",
    "start = time.time()\n",
    "RFSirus.fit(X_titanic,y_titanic)\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFSirus.feature_names_in_ = [\"Pclass\",\"Sex\",\"Age\",\"SibSp\",\"Parch\",\"Fare\"]\n",
    "show_rules(RFSirus,max_rules=25,target_class_index=1,value_mappings= {\"Sex\":{0:\"male\",1:\"female\"}})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20",
   "metadata": {},
   "source": [
    "### perfs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [1,2,3,4,5]\n",
    "categorical_features = [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_str(x):\n",
    "    return x.astype(str)\n",
    "def to_float(x):\n",
    "    return x.astype(float)\n",
    "fun_tr_str = FunctionTransformer(to_str)\n",
    "fun_tr_float = FunctionTransformer(to_float)\n",
    "numeric_transformer = Pipeline(steps=[(\"Transform_float\", fun_tr_float)])\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"Transform_str\", fun_tr_str),\n",
    "        (\"OneHot\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "    ]\n",
    ")\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFSirus = SirusClassifier(n_estimators=1000,max_depth=2,quantile=10,p0=0,max_n_rules=25,max_features=6,\n",
    "                            to_not_binarize_colindexes=[0,2,3],starting_index_one_hot=5,\n",
    "                            random_state=0,splitter=\"quantile\")\n",
    "RFSirus_pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"rf-sirus\", RFSirus)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_folds(X=X_titanic, y=y_titanic, output_path=\"reproduce-exp/titanic-folds.csv\", \n",
    "           stratified=True, n_splits=5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_from_csv(csv_path_data=\"reproduce-exp/titanic-folds.csv\",\n",
    "                        csv_path_preds=\"reproduce-exp/py-predictions-titanic.csv\",\n",
    "                        model=RFSirus_pipeline,target_col=\"target\", fold_col=\"fold\", is_clf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1,res2 = compute_metrics_csv(csv_path_data=\"reproduce-exp/titanic-folds.csv\",\n",
    "                    csv_path_preds=\"reproduce-exp/py-predictions-titanic.csv\",\n",
    "                    type_learning=\"clf\",col_preds=\"class_1\",\n",
    "                    target_col=\"target\",fold_col=\"fold\", classification_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {},
   "source": [
    "## House sales:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_house_sales,y_house_sales = load_houses_sales_reg_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "## RandomForestRegressor rules extraction\n",
    "RFSirus = SirusRegressor(n_estimators=1000,max_depth=2,quantile=10,p0=0,max_n_rules=25,max_features=15,\n",
    "                            to_not_binarize_colindexes=None,starting_index_one_hot=None,\n",
    "                            random_state=0,splitter=\"quantile\")\n",
    "RFSirus.fit(X_house_sales,y_house_sales)\n",
    "#n_estimators=1000, max_features=15, random_state=19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_rules(RFSirus,max_rules=20,is_regression=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "### perfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_folds(X=X_house_sales, y=y_house_sales, output_path=\"reproduce-exp/house_sales-folds.csv\", \n",
    "           stratified=False, n_splits=5, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {},
   "outputs": [],
   "source": [
    "RFSirus = SirusRegressor(n_estimators=1000,max_depth=2,quantile=10,p0=0,max_n_rules=25,max_features=15,\n",
    "                            to_not_binarize_colindexes=None,starting_index_one_hot=None,\n",
    "                            random_state=0,splitter=\"quantile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_validate_from_csv(csv_path_data=\"reproduce-exp/house_sales-folds.csv\",\n",
    "                        csv_path_preds=\"reproduce-exp/py-predictions-house_sales.csv\",\n",
    "                        model=RFSirus,target_col=\"target\", fold_col=\"fold\", is_clf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1,res2 = compute_metrics_csv(csv_path_data=\"reproduce-exp/house_sales-folds.csv\",\n",
    "                    csv_path_preds=\"reproduce-exp/py-predictions-house_sales.csv\",\n",
    "                    type_learning=\"reg\",col_preds=\"pred\", \n",
    "                    target_col=\"target\",fold_col=\"fold\",classification_threshold=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "res1.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "res2.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
